# Архитектура Taidon (MVP под обучение)

Цель: запустить минимально жизнеспособную платформу для учебных сценариев SQL с изолированными экземплярами, развёрнутую on-prem в Kubernetes (минимум - minikube для локальной отладки).
Диаграммы взаимодействий и внутренних компонентов: [`docs/architecture/diagrams.md`](docs/architecture/diagrams.RU.md).

## 1. Пользователи и изоляция

- Два типа пользователей: анонимные (~900 одновременных), зарегистрированные (~100). Каждому - отдельный экземпляр (БД-контейнер + снапшоты).
- Двухуровневая модель на старте: экземпляр -> аккаунт. В будущем - организации -> аккаунты -> экземпляры (GitHub-подобная иерархия).
- Секреты (Git токены) хранятся в k8s Secrets; доступ - только в границах экземпляра/аккаунта.

## 2. Сервисный состав MVP

- `frontend/main`: SPA для редактора/просмотра результатов.
- `backend/gateway`: BFF для фронтенда; терминация auth, rate limiting, маршрутизация на сервисы.
- `idp`: аутентификация (email/password/OIDC), управление сессиями токенов для анонимов/регов.
- `user-profile`: учётные записи, экземпляры, квоты/лимиты (без биллинга).
- `vcs-sync`: работа с проектами на локальной FS и опциональная синхронизация с Git (pull/push по запросу), хранение секретов доступа.
- `env-manager`: оркестрация экземпляров: создание/удаление k8s Pod/StatefulSet с PostgreSQL, монтирование снапшотов, лимиты ресурсов, сетевые policy.
- `snapshot-cache`: управление снапшотами (по хэшу цепочки SQL), политика хранения/эвикции, работа с CoW хранилищем.
- `sql-runner`: детерминированное воспроизведение цепочки SQL: вычисление head/tail, запрос снапшота у `snapshot-cache`, выполнение head, создание нового слоя.
- `audit-log`: фиксация действий пользователя/системы.
- `telemetry`: метрики/трейсы (Prometheus scrape), экспорт в Grafana.
- Отложено: `billing`, `scheduler` (фоновое обслуживание можно временно выполнять через ручные джобы или cronjob в k8s).

## 3. Ключевые потоки

- **Запуск SQL-сессии**: фронт -> gateway -> sql-runner. `sql-runner` вычисляет хэш tail, запрашивает готовый снапшот у `snapshot-cache`. Если есть - `env-manager` поднимает экземпляр из снапшота и выполняется head. Если нет - tail проигрывается, слой сохраняется в кэше, затем выполняется head. Результат/ошибки возвращаются фронту.
- **Управление экземпляром**: создание/удаление/рестарт по запросу пользователя или TTL; `env-manager` применяет ResourceQuota/LimitRange/NetworkPolicy, монтирует volume со снапшотом.
- **Работа с проектом**: локальная директория как источник истины. По запросу — синхронизация с Git через `vcs-sync` (pull/push), использование k8s Secret для токенов. Модель хранения — дерево SQL-скриптов init/seed/test/bench.

## 4. Данные и хранилища

- **Метаданные платформы**: отдельный PostgreSQL (control plane) для пользователей, экземпляров, описаний снапшотов, аудита.
- **Снапшоты**: CoW-слои для PostgreSQL-контейнеров. On-prem: локальные PV (qcow2/ZFS/btrfs/LVM-thin) с периодической материализацией; minikube — hostPath/локальный volume. В будущем — S3-совместимое объектное хранилище для хранения слоёв.
- **Логи/аудит**: централизованный лог (stdout -> Loki/ELK), аудит — отдельная таблица в control plane.
- **Секреты**: k8s Secrets + опционально интеграция с KMS/Vault (позже).

## 5. Деплой/инфраструктура

- **Кластеры**: on-prem k8s для прод/стейдж; minikube для разработки. Одинаковые манифесты/Helm-чарты, различаются значения.
- **Сетевые границы**: gateway публикуется наружу; сервисы - ClusterIP. NetworkPolicy ограничивает доступ к Postgres-экземплярам только со стороны `sql-runner`.
- **Ресурсы**: per-instance лимиты CPU/RAM; node affinity/taints для узлов с быстрым диском под снапшоты.
- **CI/CD**: сборка контейнеров, деплой через Helm/ArgoCD (при появлении).

## 6. Наблюдаемость

- Prometheus scrape: gateway, sql-runner, env-manager, snapshot-cache, idp, user-profile.
- Базовые метрики: error rate (5xx/4xx), cache hit ratio (по хэшу tail), latency запуска экземпляра и выполнения head, количество активных экземпляров, использование CPU/RAM/IO на узлах под снапшоты, размер кэша/скорость эвикции.
- Алёрты: низкий hit ratio, рост времени запуска экземпляра, переполнение PV под снапшоты, всплеск ошибок auth/Git.
- Grafana - дашборды по запросам/экземплярам/кэшу.

## 7. Ограничения и упрощения MVP

- Только PostgreSQL, без расширений; одна версия движка.
- Нет биллинга; квоты - простые (число экземпляров, лимиты ресурсов).
- Нет фонового планировщика; обслуживание кэша — через вызовы `snapshot-cache` по событию или периодический cronjob в k8s.
- Внешние интеграции ограничены Git (опционально).
- Организации и сложный RBAC - позже (пока аккаунт/экземпляр).

## 8. Открытые вопросы/риски

- Формат слоёв снапшотов для on-prem: btrfs/ZFS/LVM-thin/overlay2 — выбрать исходя из наличия в кластере и времени монтирования.
- Стратегия GC кэша без полноценного scheduler: достаточно ли cronjob в k8s для MVP.
- Политика TTL для экземпляров анонимов (чтобы держать под контролем ресурсы).
- Требуемое время cold start экземпляра и целевой SLA ответа на запрос - зафиксировать для настройки кэша/лимитов.
